{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/7188hd3d0m1cy_tl6rkgjbww0000gn/T/ipykernel_97298/2354998551.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"/chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    " \n",
    "# Creating a webdriver instance\n",
    "driver = webdriver.Chrome(\"/chromedriver.exe\")\n",
    "# This instance will be used to log into LinkedIn\n",
    " \n",
    "# Opening linkedIn's login page\n",
    "driver.get(\"https://linkedin.com/uas/login\")\n",
    " \n",
    "# waiting for the page to load\n",
    "time.sleep(5)\n",
    " \n",
    "# entering username\n",
    "username = driver.find_element(By.ID, \"username\")\n",
    " \n",
    "# In case of an error, try changing the element\n",
    "# tag used here.\n",
    " \n",
    "# Enter Your Email Address\n",
    "username.send_keys(\"bellapasta3@gmail.com\") \n",
    " \n",
    "# entering password\n",
    "pword = driver.find_element(By.ID, \"password\")\n",
    "# In case of an error, try changing the element\n",
    "# tag used here.\n",
    " \n",
    "# Enter Your Password\n",
    "pword.send_keys(\"Bella-Data12\")       \n",
    " \n",
    "# Clicking on the log in button\n",
    "# Format (syntax) of writing XPath -->\n",
    "# //tagname[@attribute='value']\n",
    "driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "# In case of an error, try changing the\n",
    "# XPath used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening jobs webpage\n",
    "#added from other code\n",
    "# position = \"data scientist\"\n",
    "local = \"Saudi Arabia\"\n",
    "driver.get(\n",
    "    f\"https://www.linkedin.com/jobs/search/?currentJobId=3591637569&geoId=100459316&keywords=system%20engineer&location=Saudi%20Arabia&refresh=true\")\n",
    "# waiting load\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 2\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 3\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 4\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 5\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 6\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 7\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 8\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 9\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 10\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 11\n",
      "25\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Page 12\n",
      "18\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "Page 13\n",
      "18\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "Page 14\n",
      "18\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "Page 15\n",
      "17\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "Page 16\n",
      "17\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "contract_list = []\n",
    "company_list= []\n",
    "date_list = []\n",
    "job_level_list = []\n",
    "location_list = []\n",
    "title_list = []\n",
    "job_Id =0\n",
    "disc_list =[]\n",
    "for i in range(1,17):\n",
    "    # click button to change the job list\n",
    "    print(f'Page {i}')\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, f'//button[@aria-label=\"Page {i}\"]').click()\n",
    "    # each page show us some jobs, sometimes show 25, others 13 or 21 ¯\\_(ツ)_/¯\n",
    "        jobs_lists = driver.find_element(By.CLASS_NAME,\n",
    "        'scaffold-layout__list-container')  # here we create a list with jobs\n",
    "        jobs = jobs_lists.find_elements(By.CLASS_NAME,\n",
    "        'jobs-search-results__list-item')  # here we select each job to count\n",
    "        # print(len(jobs))\n",
    "    #  #job Title\n",
    "    #     job_title = jobs_lists.find_elements(By.CLASS_NAME,\n",
    "    #         'job-card-list__title') \n",
    "    #     for title in job_title:\n",
    "    #         title_list.append(title.text.strip())\n",
    "\n",
    "    # # Job company name\n",
    "    #     job_comany = jobs_lists.find_elements(By.CLASS_NAME,\n",
    "    #     'job-card-container__company-name') \n",
    "    #     for company in job_comany:\n",
    "    #         company_list.append(company.text.strip())\n",
    "\n",
    "    # # Job location\n",
    "    #     job_location = jobs_lists.find_elements(By.CLASS_NAME,\n",
    "    #         'job-card-container__metadata-item') \n",
    "    # # for loc in job_location:\n",
    "    # #     location_list.append(loc.text.strip())\n",
    "    except:\n",
    "        pass\n",
    "    # waiting load\n",
    "    # time.sleep(1)\n",
    "    # looping in each Job detailes \n",
    "    jobNumber = len(jobs)\n",
    "    print(jobNumber) \n",
    "\n",
    "    for job in range(1, jobNumber+1):\n",
    "        # print(job)\n",
    "        # job click\n",
    "        try:\n",
    "            print(job)\n",
    "            driver.find_element(By.XPATH, \n",
    "                f'/html/body/div[5]/div[3]/div[4]/div/div/main/div/div[1]/div/ul/li[{job}]/div/div[1]/div[1]/div[2]/div[1]/a').click()\n",
    "        # job title    \n",
    "            job_title = driver.find_element(By.XPATH, \n",
    "                f'/html/body/div[5]/div[3]/div[4]/div/div/main/div/div[1]/div/ul/li[{job}]/div/div[1]/div[1]/div[2]/div[1]/a')\n",
    "            titlesoup = BeautifulSoup(job_title.get_attribute('outerHTML'), 'html.parser').text\n",
    "            title_list.append(titlesoup)\n",
    "\n",
    "\n",
    "            job_location = driver.find_element(By.XPATH, \n",
    "                f'//*[@id=\"main\"]/div/div[2]/div/div[2]/div[1]/div/div[1]/div/div[1]/div[1]/div[1]/span[1]/span[2]')\n",
    "            locationsoup = BeautifulSoup(job_location.get_attribute('outerHTML'), 'html.parser').text\n",
    "            location_list.append(locationsoup)\n",
    "            try:\n",
    "        # job level    \n",
    "                job_level = driver.find_element(By.XPATH, \n",
    "                f'//*[@id=\"main\"]/div/div[2]/div/div[2]/div[1]/div/div[1]/div/div[1]/div[1]/div[2]/ul/li[1]')\n",
    "                levelsoup = BeautifulSoup(job_level.get_attribute('outerHTML'), 'html.parser').text\n",
    "                job_level_list.append(levelsoup)\n",
    "            except:\n",
    "                job_level_list.append(None)\n",
    "                pass\n",
    "            try:\n",
    "        # job date    \n",
    "                job_date = driver.find_element(By.XPATH, \n",
    "                f'//*[@id=\"main\"]/div/div[2]/div/div[2]/div[1]/div/div[1]/div/div[1]/div[1]/div[1]/span[2]/span[1]')\n",
    "                datesoup = BeautifulSoup(job_date.get_attribute('outerHTML'), 'html.parser').text\n",
    "                date_list.append(datesoup)\n",
    "            except:\n",
    "                date_list.append(None)\n",
    "                pass\n",
    "            try:\n",
    "        # job company     \n",
    "                job_comany = driver.find_element(By.XPATH, \n",
    "                f'//*[@id=\"main\"]/div/div[2]/div/div[2]/div[1]/div/div[1]/div/div[1]/div[1]/div[1]/span[1]/span[1]')\n",
    "                companysoup = BeautifulSoup(job_comany.get_attribute('outerHTML'), 'html.parser').text\n",
    "                company_list.append(companysoup)\n",
    "            except:\n",
    "                company_list.append(None)\n",
    "                pass\n",
    "            try:\n",
    "        # job contract     \n",
    "                job_contract = driver.find_element(By.XPATH, \n",
    "                f'//*[@id=\"main\"]/div/div[2]/div/div[2]/div[1]/div/div[1]/div/div[1]/div[1]/div[1]/span[2]')\n",
    "                contractsoup = BeautifulSoup(job_contract.get_attribute('outerHTML'), 'html.parser').text\n",
    "                contract_list.append(contractsoup)\n",
    "            except:\n",
    "                contract_list.append(None)\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                job_desc = driver.find_elements(By.CLASS_NAME,'jobs-description__content') \n",
    "                for desc in job_desc:\n",
    "                    disc_list.append(desc.text.strip())\n",
    "            except:\n",
    "                disc_list.append(None)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            pass\n",
    "\n",
    "\n",
    "        # if (len(titlesoup) !=0 and len(locationsoup) !=0 and len(levelsoup) !=0 and len(datesoup) !=0 and len(company_list) !=0 and len(contractsoup) !=0):\n",
    "        #     contract_list.append([contractsoup])\n",
    "        #     company_list.append([companysoup])\n",
    "        #     date_list.append([datesoup])\n",
    "        #     job_level_list.append([levelsoup])\n",
    "        #     location_list.append([locationsoup])\n",
    "        #     title_list.append([titlesoup])\n",
    "        # else:\n",
    "        #     continue\n",
    "\n",
    "# //*[@id=\"main\"]/div/div[2]/div/div[2]/div[1]/div/div[1]/div/div[1]/div[1]/div[1]/span[2]/span[1]\n",
    "\n",
    "        # Select job description by Path\n",
    "        # job_desc = driver.find_elements(By.CLASS_NAME,'jobs-description__content') \n",
    "        # for desc in job_desc:\n",
    "        #     disc_list.append([job_Id,desc.text.strip()])\n",
    "\n",
    "        # # Get text\n",
    "        # soup = BeautifulSoup(job_desc.get_attribute(\n",
    "        #      'outerHTML'), 'html.parser')\n",
    "        # # add text to list\n",
    "        # disc_list.append([job_Id,soup])\n",
    "    # print('job_level_list size' ,len(job_level_list))\n",
    "    # print('disc_list size ',len(disc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 117, 117, 117, 117, 117, 117)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_list), len(location_list), len(company_list), len(job_level_list), len(contract_list), len(date_list), len(disc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n                1 week ago\\n              \\n\\n                    Over 200 applicants\\n                \\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contract_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalCharacterError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalCharacterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(title_list,company_list,location_list ,job_level_list, date_list,disc_list,)),\n\u001b[1;32m      2\u001b[0m         columns \u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mjob Title\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mjob Company\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mJob Location\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mJob level\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mJob describation\u001b[39m\u001b[39m'\u001b[39m,]) \n\u001b[0;32m----> 3\u001b[0m df\u001b[39m.\u001b[39;49mto_excel(\u001b[39m'\u001b[39;49m\u001b[39mSYSTEM ENGINEER Job Posting.xlsx\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/generic.py:2374\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcel\u001b[39;00m \u001b[39mimport\u001b[39;00m ExcelFormatter\n\u001b[1;32m   2363\u001b[0m formatter \u001b[39m=\u001b[39m ExcelFormatter(\n\u001b[1;32m   2364\u001b[0m     df,\n\u001b[1;32m   2365\u001b[0m     na_rep\u001b[39m=\u001b[39mna_rep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2372\u001b[0m     inf_rep\u001b[39m=\u001b[39minf_rep,\n\u001b[1;32m   2373\u001b[0m )\n\u001b[0;32m-> 2374\u001b[0m formatter\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m   2375\u001b[0m     excel_writer,\n\u001b[1;32m   2376\u001b[0m     sheet_name\u001b[39m=\u001b[39;49msheet_name,\n\u001b[1;32m   2377\u001b[0m     startrow\u001b[39m=\u001b[39;49mstartrow,\n\u001b[1;32m   2378\u001b[0m     startcol\u001b[39m=\u001b[39;49mstartcol,\n\u001b[1;32m   2379\u001b[0m     freeze_panes\u001b[39m=\u001b[39;49mfreeze_panes,\n\u001b[1;32m   2380\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m   2381\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2382\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/formats/excel.py:950\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[1;32m    947\u001b[0m     need_save \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 950\u001b[0m     writer\u001b[39m.\u001b[39;49m_write_cells(\n\u001b[1;32m    951\u001b[0m         formatted_cells,\n\u001b[1;32m    952\u001b[0m         sheet_name,\n\u001b[1;32m    953\u001b[0m         startrow\u001b[39m=\u001b[39;49mstartrow,\n\u001b[1;32m    954\u001b[0m         startcol\u001b[39m=\u001b[39;49mstartcol,\n\u001b[1;32m    955\u001b[0m         freeze_panes\u001b[39m=\u001b[39;49mfreeze_panes,\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    957\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     \u001b[39m# make sure to close opened file handles\u001b[39;00m\n\u001b[1;32m    959\u001b[0m     \u001b[39mif\u001b[39;00m need_save:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/io/excel/_openpyxl.py:496\u001b[0m, in \u001b[0;36mOpenpyxlWriter._write_cells\u001b[0;34m(self, cells, sheet_name, startrow, startcol, freeze_panes)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[39mfor\u001b[39;00m cell \u001b[39min\u001b[39;00m cells:\n\u001b[1;32m    493\u001b[0m     xcell \u001b[39m=\u001b[39m wks\u001b[39m.\u001b[39mcell(\n\u001b[1;32m    494\u001b[0m         row\u001b[39m=\u001b[39mstartrow \u001b[39m+\u001b[39m cell\u001b[39m.\u001b[39mrow \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, column\u001b[39m=\u001b[39mstartcol \u001b[39m+\u001b[39m cell\u001b[39m.\u001b[39mcol \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    495\u001b[0m     )\n\u001b[0;32m--> 496\u001b[0m     xcell\u001b[39m.\u001b[39mvalue, fmt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value_with_fmt(cell\u001b[39m.\u001b[39mval)\n\u001b[1;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m fmt:\n\u001b[1;32m    498\u001b[0m         xcell\u001b[39m.\u001b[39mnumber_format \u001b[39m=\u001b[39m fmt\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openpyxl/cell/cell.py:215\u001b[0m, in \u001b[0;36mCell.value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m@value\u001b[39m\u001b[39m.\u001b[39msetter\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalue\u001b[39m(\u001b[39mself\u001b[39m, value):\n\u001b[1;32m    214\u001b[0m     \u001b[39m\"\"\"Set the value and infer type and display options.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bind_value(value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openpyxl/cell/cell.py:194\u001b[0m, in \u001b[0;36mCell._bind_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumber_format \u001b[39m=\u001b[39m get_time_format(t)\n\u001b[1;32m    193\u001b[0m \u001b[39melif\u001b[39;00m dt \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 194\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_string(value)\n\u001b[1;32m    195\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    196\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_type \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/openpyxl/cell/cell.py:162\u001b[0m, in \u001b[0;36mCell.check_string\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    160\u001b[0m value \u001b[39m=\u001b[39m value[:\u001b[39m32767\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnext\u001b[39m(ILLEGAL_CHARACTERS_RE\u001b[39m.\u001b[39mfinditer(value), \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mraise\u001b[39;00m IllegalCharacterError\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[0;31mIllegalCharacterError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(list(zip(title_list,company_list,location_list ,job_level_list, date_list,disc_list,)),\n",
    "        columns =['job Title','job Company','Job Location','Job level', 'Date','Job describation',]) \n",
    "df.to_excel('SYSTEM ENGINEER Job Posting.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job Title</th>\n",
       "      <th>job Company</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Job level</th>\n",
       "      <th>Date</th>\n",
       "      <th>Job describation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n              NEOM Group Data Protection Dir...</td>\n",
       "      <td>\\n\\n                    NEOM\\n                ...</td>\n",
       "      <td>\\n                Neom, Tabuk, Saudi Arabia\\n ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFull-time · Director\\n\\n</td>\n",
       "      <td>\\n                3 days ago\\n</td>\n",
       "      <td>About the job\\nNEOM Group Data Protection Dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n              Data Scientist\\n</td>\n",
       "      <td>\\n\\n                    Maven Insights\\n      ...</td>\n",
       "      <td>\\n                Riyadh, Saudi Arabia\\n      ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFull-time\\n\\n</td>\n",
       "      <td>\\n                1 week ago\\n</td>\n",
       "      <td>About the job\\nAbout Us\\nMaven Insights is a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n              ICQA Researcher, ICQA\\n       ...</td>\n",
       "      <td>\\n\\n                    Amazon\\n              ...</td>\n",
       "      <td>\\n                Riyadh, Riyadh, Saudi Arabia...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFull-time\\n\\n</td>\n",
       "      <td>\\n                5 days ago\\n</td>\n",
       "      <td>About the job\\nDescription\\n\\nThe Data and Rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n              Lead Online Programmer\\n      ...</td>\n",
       "      <td>\\n\\n                    Savvy Games Studios\\n ...</td>\n",
       "      <td>\\n                Riyadh, Saudi Arabia\\n      ...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFull-time · Mid-Senior l...</td>\n",
       "      <td>\\n                4 weeks ago\\n</td>\n",
       "      <td>About the job\\nSavvy Games Studios (SGS) missi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n              Data Scientist\\n</td>\n",
       "      <td>\\n\\n                    Halian\\n              ...</td>\n",
       "      <td>\\n                Riyadh, Riyadh, Saudi Arabia...</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContract · Entry level\\n\\n</td>\n",
       "      <td>\\n                2 months ago\\n</td>\n",
       "      <td>About the job\\nOur Client\\n\\nWe are working wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job Title  \\\n",
       "0  \\n              NEOM Group Data Protection Dir...   \n",
       "1       \\n              Data Scientist\\n               \n",
       "2  \\n              ICQA Researcher, ICQA\\n       ...   \n",
       "3  \\n              Lead Online Programmer\\n      ...   \n",
       "4       \\n              Data Scientist\\n               \n",
       "\n",
       "                                         job Company  \\\n",
       "0  \\n\\n                    NEOM\\n                ...   \n",
       "1  \\n\\n                    Maven Insights\\n      ...   \n",
       "2  \\n\\n                    Amazon\\n              ...   \n",
       "3  \\n\\n                    Savvy Games Studios\\n ...   \n",
       "4  \\n\\n                    Halian\\n              ...   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  \\n                Neom, Tabuk, Saudi Arabia\\n ...   \n",
       "1  \\n                Riyadh, Saudi Arabia\\n      ...   \n",
       "2  \\n                Riyadh, Riyadh, Saudi Arabia...   \n",
       "3  \\n                Riyadh, Saudi Arabia\\n      ...   \n",
       "4  \\n                Riyadh, Riyadh, Saudi Arabia...   \n",
       "\n",
       "                                           Job level  \\\n",
       "0     \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFull-time · Director\\n\\n   \n",
       "1                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFull-time\\n\\n   \n",
       "2                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFull-time\\n\\n   \n",
       "3  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFull-time · Mid-Senior l...   \n",
       "4   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContract · Entry level\\n\\n   \n",
       "\n",
       "                                             Date  \\\n",
       "0    \\n                3 days ago\\n                 \n",
       "1    \\n                1 week ago\\n                 \n",
       "2    \\n                5 days ago\\n                 \n",
       "3   \\n                4 weeks ago\\n                 \n",
       "4  \\n                2 months ago\\n                 \n",
       "\n",
       "                                    Job describation  \n",
       "0  About the job\\nNEOM Group Data Protection Dire...  \n",
       "1  About the job\\nAbout Us\\nMaven Insights is a b...  \n",
       "2  About the job\\nDescription\\n\\nThe Data and Rep...  \n",
       "3  About the job\\nSavvy Games Studios (SGS) missi...  \n",
       "4  About the job\\nOur Client\\n\\nWe are working wi...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract  a Dataframe to Excel\n",
    "df2.to_excel('Saudi Job 2.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
